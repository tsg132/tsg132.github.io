
<!DOCTYPE html>
<html>
<head>
  <title> Project 4: Fun With Diffusion </title>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 20px;
    }
    img {
      max-width: 100%;
      height: auto;
    }
  </style>
</head>
<body>
  <h1> Image Generation with DeepFloyd and Implementation of a Diffusion Denoiser </h1>
  <h2> Part 0: Setup </h2>

  <p> In the first part of this project, we will be generating images with a pre-trained denoising model based on two unets, stage_1 unet can generate 64x64 pixel images and stage_2 unet can generate 256 x 256 pixel images. We access the model through Hugging Face. The model also takes in an argument of num_inference, which increases the steps in the denoising process. This implies that we expect images generated with higher 
    num_inferences to be denoised further and be somewhat of higher quality and more detailed. Below is 2 sets of 3 images generated with different num_inferences, for the first set, num_inference is 20, for the second set, num_inference is 80.
  </p>

  <h2>Images with num_inference = 20</h2>

  <img src="5a_part0_images/Unknown-34.png"> 

  <img src="5a_part0_images/Unknown-37.png">

  <img src="5a_part0_images/Unknown-36.png">


  <h2>Images with num_inference = 80</h2>

  <img src="5a_part0_images/Unknown-44.png">

  <img src="5a_part0_images/Unknown-45.png">

  <img src="5a_part0_images/Unknown-46.png">


  <h2> Part 1: Sampling Loops </h2>

  <p> In this part, I wrote sampling loops from the model that helped me generate images. </p>

  <h2> 1.1 Implementing the forward process </h2>

  <p>We have a list of precomputed alphas, alpha_bars, and betas generated by the former 2 in accordance with the DDPM paper equations. In diffusion, we assume
  that we can recover a noisy image by denoising it, so the question now becomes to learn the noise added at each time step, so that we could recover the original image. To do that,
  we progressively noise a given image, and then subtract the estimated noise from it to get back the original image. If we train a model for this, we can simply recover any image that resembled the images the model
  was trained with, which is the task of the second part. For this part, we simply noise an image adhering to the below equation. Notice that when t = 0, the second term in the equation should be zero since we should recover the
  original image in the first timestep, thus, as t approaches 0, alpha_bar_t aproaches 1 and vice versa. </p>

  
  <img src="equations/parta_equations/eq1.png">

  <h2> Associated images </h2>

  <img src="5a_part11_images/Unknown-34.png">

  <img src="5a_part11_images/Unknown-35.png">

  <img src="5a_part11_images/Unknown-36.png">

  <img src="5a_part11_images/Unknown-37.png">



  <h2> 1.2 Classical Denoising </h2>

  <p> In this part we show that using Gaussian Blurring is useless to recover the images from timesteps [250, 500, 750] or recover any noisy image for that matter! </p>

  <h2> Associated Images </h2>
  <img src="5a_part12_images/Unknown-34.png">
  <img src="5a_part12_images/Unknown-35.png">

  <img src="5a_part12_images/Unknown-36.png">
  

  <h2> 1.3 Implementing One Step Denoising </h2>

  <p>
    Here, we implement one step denoising, which is simply rearranging the second equation to obtain x_0, original image. To do this, we feed noisy images at different timesteps ([250, 500, 750]) to get the noise estimate from the diffusion model, and put this
    noise estimate to the above equation and with x_t being our noisy image, we recover the original image.
  </p>

  <h2> Associated Images </h2>

  <img src="5a_part13_images/Unknown-34.png">

  <img src="5a_part13_images/Unknown-35.png">
  <img src="5a_part13_images/Unknown-36.png">

  <h2> 1.4 Implementing Iterative Denoising </h>
  <p>

    Although the images above look good, we can do better with iterative denoising. Here, we adhere to the below equation. To get x_t, we input the noisy image to the model to get the noise estimate and recover following the same procedure as one step denoising, then we input this recovered image to the iterative denoising loop getting a iteratively denoised estimate.
    We follow this procedure with strided time steps for efficiency until we get the clean image. Here we start the strided time steps with i_start = 10, so we start off with a noisy image but not pure noise, just the noised image of the image that we are trying to regenerate. This can be viewed as interpolation in the image manifold, we are basically cruising along the 
    line below from x_t to x_0 according to our model.
  </p>

  <img src="equations/parta_equations/eq2.png">

  <img src="equations/parta_equations/eq3.png">

  <h2> Associated Images </h2>

        <img src="5a_part14_images/Unknown-34.png">

      <img src="5a_part14_images/Unknown-35.png">
  <img src="5a_part14_images/Unknown-36.png">

  <img src="5a_part14_images/Unknown-37.png">

  <img src="5a_part14_images/Unknown-38.png">

  <img src="5a_part14_images/Unknown-39.png">

  <img src="5a_part14_images/Unknown-40.png">

  <img src="5a_part14_images/Unknown-41.png">

  
  <h2> 1.5 Diffusion Model Sampling </h2>

  

  <p>
    Notice that if we set i_start = 0, then we start off with pure noise, which generates an image from scratch. Since DeepFloyd is also a text model, we can generate images from scratch with i_start = 0 and unconditional prompt "a high quality photo".
  </p>

  
  <h2> Associated Images</h2>

  <h2> Classifier Free Guidance </h2>
  <p> 
    Apperantly, getting noise estimates for a conditional prompt and an unconditional prompt, and combining them according to the below equation with strength measure gamma, we can get better quality images even when we start from scratch. In this case, the conditional prompt is "a high quality photo" and the unconditional prompt is the empty string with gamma = 7.
  </p>

  <img src="equations/parta_equations/eq4.png">
  

  <h2> Associated Images </h2>

  <img src="5a_part15_images/Unknown-34.png">

  <img src="5a_part15_images/Unknown-35.png">
  <img src="5a_part15_images/Unknown-36.png">
  <img src="5a_part15_images/Unknown-37.png">

  <img src="5a_part15_images/Unknown-38.png">


  <h2> Image to image Translation </h2>

  <p>
    Here, we show the results of iterative classifier free guidance below for i_start values in [1, 3, 5, 7, 10, 20] and conditional prompt "a high quality photo".
  </p>

  <h2> Associated Images </h2>


  <h2> Associated Images </h2>

  <img src="5a_part16_images/Unknown-34.png">

  <img src="5a_part16_images/Unknown-35.png">

  <img src="5a_part16_images/Unknown-36.png">

  <img src="5a_part16_images/Unknown-37.png">

  <img src="5a_part16_images/Unknown-38.png">

  <h2> All the images for the rest of the project </h2>

  <p> I am very time constrained right now because I am taking the course PNP and this is the last day to submit it, here all the images for the projects are included but please refer to the website I created for better webpage</p>

  <h2>All the images for part b</h2>

    <img src="project_5b_images/image0.png">
  <img src="project_5b_images/noised_signa0.png">
  <img src="project_5b_images/noised_signa2.png">

  <img src="project_5b_images/noised_signa4.png">

  <img src="project_5b_images/noised_signa5.png">

  <img src="project_5b_images/noised_signa6.png">

  <img src="project_5b_images/noised_signa8.png">

  <img src="project_5b_images/noised_signa10.png">

  <img src="project_5b_images/time_and_class_conditional_5.png">

  <img src="project_5b_images/time_and_class_conditional_20.png">

  <img src="project_5b_images/time_and_class_conditioned_regen_5.png">

  <img src="project_5b_images/time_and_class_conditioned_regen_20.png">

  <img src="project_5b_images/time_conditioned_loss_5.png">

  <img src="project_5b_images/time_conditioned_loss_20.png">

  <img src="project_5b_images/time_conditioned_regen_5.png">

  <img src="project_5b_images/time_conditioned_regen_20.png">

  <img src="project_5b_images/unconditional_epoch1.png">

  <img src="project_5b_images/unconditional_epoch5.png">

  <img src="project_5b_images/unconditional_log_training_loss.png">

  <img src="project_5b_images/unconditional_regen_sigma0.png">

  <img src="project_5b_images/unconditional_regen_sigma2.png">

  <img src="project_5b_images/unconditional_regen_sigma4.png">

  <img src="project_5b_images/unconditional_regen_sigma5.png">

  <img src="project_5b_images/unconditional_regen_sigma6.png">

  <img src="project_5b_images/unconditional_regen_sigma8.png">

  <img src="project_5b_images/unconditional_regen_sigma10.png">
    
<!--   <h2> Editing Hand-Drawn and Web Images </h2>

  <p>
    Here, I show the results of iterative classifier free guidance below with one web image and two hand drawn images of my own.
  </p>


  <h2> Associated Images </h2>

  

  <h2> Inpainting </h2>

  <p> We can also do inpainting, which is leaving off a certain part of the image unchanged and the filling the rest with the generated image. We can easily accomplish this by creating a mask and multiply the denoised image with the mask and multiplying the original image with (1 - mask) adhering to the equation below. </p>

  <img src="equations/parta_equations/eq5.png">


  <h2> Associated Images </h2>

  <h2> Text-Conditioned Image-to-image Translation </h2>

  <p> Here, we generate images with prompts with different noise levels for input images. To do this, we simply change the conditional prompt to any prompt we'd like and denoise from the same levels as above. For this part
  I use the prompt "a rocket ship", for three of my images. </p>

  <h2> Associated Images </h2>

  <h2> Visual Anagrams </h2>

  <p> With this models, for two different prmopts we get two noise estimates adhering the equation below and take their average to be our final noise estimate. This way we denoise an image that looks like prompt 1 upright, and like prompt 2 rotated. For this part, I use the prompts ("an oil painting of people around a campfire", an oil painting of an old man), ("a coffee cup with a handle", a classic golden bell with a curved handle"), ("an oil painting of a snowy mountain village", "a rocket ship"), respectively for the below images. </p>

  <img src="equations/parta_equations/eq6.png">

  <h2> Associated Images </h2>

  <h2> Hybrid Images </h2>

  <p> Just like project 3, we can generate hybrid images with this model, adhering to the equations below. This simply means that we get two seperate noise estimates and lowpass one of them with a gaussian blur and highpass the other one with Gaussian as well and add them to get a hybrid noise estimate for the two different prompts and denoise from there. I use the ("a lithograph of a skull", "a lithograph of waterfalls"), ("a rocket ship", "a pencil"), ("a detailed photograph of a full moon with craters", "a simple round clock on black background") respectively, the results are below. </p>

  <img src="equations/parta_equations/eq7.png">

  <h2> Associated Images </h2>

  <h2> Part: B, 1: Training a single Step denoising UNet </h2>

  <p> To implement the unet, we follow the below UNet architecture using the necessary tools from pytorch and GPUs from collab. The loss function L, which is used for backpropagation later to train the UNet better.</p>

  <img src="equations/partb_equations/eq1.png">

  <img src="equations/partb_equations/eq2.png">

  <img src="equations/partb_equations/eq3.png">

  <h2> Using the UNet to train a Denoiser </h2>

  <p> After implementing the model above, </p> -->

  

  
</body>
</html>

